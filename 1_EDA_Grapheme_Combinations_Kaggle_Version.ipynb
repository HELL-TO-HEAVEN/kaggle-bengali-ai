{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Bengali AI Dataset\n",
    "# Grapheme Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains images of individual hand-written [Bengali characters](https://en.wikipedia.org/wiki/Bengali_alphabet). \n",
    "Bengali characters (graphemes) are written by combining three components: a grapheme_root\n",
    ", vowel_diacritic, and consonant_diacritic. Your challenge is to classify the components of the grapheme in each\n",
    "image. There are roughly 10,000 possible graphemes, of which roughly 1,000 are represented in the training set. The\n",
    "test set includes some graphemes that do not exist in train but has no new grapheme components. It takes a lot of\n",
    "volunteers filling out [sheets like this](https://github.com/BengaliAI/graphemePrepare/blob/master/collection/A4/form_1.jpg)\n",
    "to generate a useful amount of real data; focusing the problem on the grapheme components rather than on recognizing\n",
    "whole graphemes should make it possible to assemble a Bengali OCR system without handwriting samples for all 10,000\n",
    "graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import Markdown, HTML\n",
    "# from src.jupyter import grid_df_display, combination_matrix\n",
    "\n",
    "pd.set_option('display.max_columns',   500)\n",
    "pd.set_option('display.max_colwidth',   -1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Library Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side/50899244#50899244\n",
    "import pandas as pd\n",
    "from IPython.display import display,HTML\n",
    "\n",
    "def grid_df_display(list_dfs, rows = 2, cols=3, fill = 'cols'):\n",
    "    if fill not in ['rows', 'cols']: print(\"grid_df_display() - fill must be one of: 'rows', 'cols'\")\n",
    "\n",
    "    html_table = \"<table style='width:100%; border:0px'>{content}</table>\"\n",
    "    html_row   = \"<tr style='border:0px'>{content}</tr>\"\n",
    "    html_cell  = \"<td style='width:{width}%;vertical-align:top;border:0px'>{{content}}</td>\"\n",
    "    html_cell  = html_cell.format(width=100/cols)\n",
    "\n",
    "    cells = [ html_cell.format(content=df.to_html()) for df in list_dfs[:rows*cols] ]\n",
    "    cells += cols * [html_cell.format(content=\"\")] # pad\n",
    "\n",
    "    if fill == 'rows':   # fill in rows first (first row: 0,1,2,... col-1)\n",
    "        grid = [ html_row.format(content=\"\".join(cells[i:i+cols])) for i in range(0,rows*cols,cols)]\n",
    "    elif fill == 'cols': # fill columns first (first column: 0,1,2,..., rows-1)\n",
    "        grid = [ html_row.format(content=\"\".join(cells[i:rows*cols:rows])) for i in range(0,rows)]\n",
    "    else:\n",
    "        grid = []\n",
    "\n",
    "    # noinspection PyTypeChecker\n",
    "    display(HTML(html_table.format(content=\"\".join(grid))))\n",
    "\n",
    "    # add extra dfs to bottom\n",
    "    [display(list_dfs[i]) for i in range(rows*cols,len(list_dfs))]\n",
    "\n",
    "\n",
    "if __name__ == \"main\":\n",
    "    list_dfs = []\n",
    "    list_dfs.extend((pd.DataFrame(2*[{\"x\":\"hello\"}]),\n",
    "                     pd.DataFrame(2*[{\"x\":\"world\"}]),\n",
    "                     pd.DataFrame(2*[{\"x\":\"gdbye\"}])))\n",
    "\n",
    "    grid_df_display(3*list_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.formats.style import Styler\n",
    "\n",
    "\n",
    "def combination_matrix(dataset: pd.DataFrame, x: str, y: str, z: str,\n",
    "                       format=None, unique=True) -> Union[pd.DataFrame, Styler]:\n",
    "    \"\"\"\n",
    "    Returns a combination matrix, showing all valid combinations between three DataFrame columns.\n",
    "    Sort of like a heatmap, but returning lists of (optionally) unique values\n",
    "\n",
    "    :param dataset: The dataframe to create a combination_matrx from\n",
    "    :param x: column name to use for the X axis\n",
    "    :param y: column name to use for the Y axis\n",
    "    :param z: column name to use for the Z axis (values that appear in the cells)\n",
    "    :param format: '', ', '-', ', '\\n'    = format value lists as \"\".join() string\n",
    "                    str, bool, int, float = cast value lists\n",
    "    :param unique:  whether to return only unique values or not - eg: combination_matrix(unique=False).applymap(sum)\n",
    "    :return: returns nothing\n",
    "    \"\"\"\n",
    "    unique_y = sorted(dataset[y].unique())\n",
    "    combinations = pd.DataFrame({\n",
    "        n: dataset.query(f'{y} == {n}')\n",
    "            .groupby(x)[z]\n",
    "            .pipe(lambda df: df.unique() if unique else df )\n",
    "            .apply(list)\n",
    "            .apply(sorted)\n",
    "        for n in unique_y\n",
    "    }).T\n",
    "\n",
    "    if isinstance(format, str):\n",
    "        combinations = combinations.applymap(\n",
    "            lambda cell: f\"{format}\".join([str(value) for value in list(cell) ])\n",
    "            if isinstance(cell, list) else cell\n",
    "        )\n",
    "    if format == str:   combinations = combinations.applymap(lambda cell: str(cell)      if isinstance(cell, list) and len(cell) > 0 else ''     )\n",
    "    if format == bool:  combinations = combinations.applymap(lambda cell: True           if isinstance(cell, list) and len(cell) > 0 else False  )\n",
    "    if format == int:   combinations = combinations.applymap(lambda cell: int(cell[0])   if isinstance(cell, list) and len(cell)     else ''     )\n",
    "    if format == float: combinations = combinations.applymap(lambda cell: float(cell[0]) if isinstance(cell, list) and len(cell)     else ''     )\n",
    "\n",
    "    combinations.index.rename(y, inplace=True)\n",
    "    combinations.fillna('', inplace=True)\n",
    "    if format == '\\n':\n",
    "        return combinations.style.set_properties(**{'white-space': 'pre-wrap'})  # needed for display\n",
    "    else:\n",
    "        return combinations  # Allows for subsequent .applymap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../input/bengaliai-cv19/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../input/bengaliai-cv19/train.csv'); \n",
    "# for key in ['grapheme_root','vowel_diacritic','consonant_diacritic','grapheme']:\n",
    "#     dataset[key] = dataset[key].astype('category')  # ensures groupby().count() shows zeros\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: How many unique graphemes are there?\n",
    "\n",
    "There are 168 grapheme roots, 11 vowel diacritics, 7 consonant diacritics, and 1295 unique graphemes within the 20k training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = dataset.apply(lambda col: col.nunique()); unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Can all diacritics be used with any grapheme?\n",
    "\n",
    "- Documentation claims 10,000+ possible graphemes, which is indeed `168 * 11 * 7 = 12936`\n",
    "\n",
    "- Assuming that the training dataset is representative of common usage, \n",
    "  then certian combinations may never (or rarely) be used in practice).\n",
    "\n",
    "- Unconfirmed Theory: the physics of the human mouth may make such combinations unpronouncable.\n",
    "\n",
    "- Conclusion: it may be able infer excluded combinations using simple logical rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vowel / Consonant Combinations:\n",
    "- Vowel #0 and Consonant #0 combine with everything\n",
    "- Vowels #3, #5, #6, #8 have limited combinations with Consonants \n",
    "- Consonant #3 is never combined except with Vowel #0\n",
    "- Consonant #6 only combineds with Vowels #0 and #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_matrix(dataset, x='consonant_diacritic', y='vowel_diacritic', z='consonant_diacritic', unique=False).applymap(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grapheme Root Combinations:\n",
    "- Vowel #0 and Consonant #0 combine with (nearly) everything\n",
    "- ALL Roots combine with some Consonant #0\n",
    "- Several Roots do NOT combine with Vowel #0 = [26, 28, 33, 34, 73, 82, 108, 114, 126, 152, 157, 158, 163]\n",
    "- Several Roots do combine with ALL Vowels = [13, 23, 64, 72, 79, 81, 96, 107, 113, 115, 133, 147]}\n",
    "- Only Root #107 combines with ALL Consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_vowels            = dataset.groupby('grapheme_root')['vowel_diacritic'].unique().apply(sorted).to_frame().T\n",
    "root_consonants        = dataset.groupby('grapheme_root')['consonant_diacritic'].unique().apply(sorted).to_frame().T\n",
    "root_vowels_values     = root_vowels.applymap(len).values.flatten()\n",
    "root_consonants_values = root_consonants.applymap(len).values.flatten()\n",
    "\n",
    "display(root_vowels)\n",
    "display({\n",
    "    \"mean\":   root_vowels_values.mean(),\n",
    "    \"median\": np.median( root_vowels_values ),\n",
    "    \"min\":    root_vowels_values.min(),\n",
    "    \"max\":    root_vowels_values.max(),\n",
    "    \"unique_vowels\":    unique['vowel_diacritic'],\n",
    "    \"root_combine_0\":   sum([ 0 in lst for lst in root_vowels.values.flatten() ]),\n",
    "    \"unique_roots\":     unique['grapheme_root'],\n",
    "    \"root_combine_not_0\": str([ index for index, lst in enumerate(root_vowels.values.flatten()) if 0 not in lst ]),    \n",
    "    \"root_combine_all\":       [ index for index, lst in enumerate(root_vowels.values.flatten()) if len(lst) == unique['vowel_diacritic'] ],\n",
    "})\n",
    "# print('--------------------')\n",
    "display(root_consonants)\n",
    "display({\n",
    "    \"mean\":   root_consonants_values.mean(),\n",
    "    \"median\": np.median( root_consonants_values ),\n",
    "    \"min\":    root_consonants_values.min(),\n",
    "    \"max\":    root_consonants_values.max(),\n",
    "    \"unique_consonants\":  unique['consonant_diacritic'],\n",
    "    \"root_combine_0\": sum([ 0 in lst for lst in root_consonants.values.flatten() ]),\n",
    "    \"unique_roots\":   unique['grapheme_root'],\n",
    "    \"root_combine_not_0\": str([ index for index, lst in enumerate(root_consonants.values.flatten()) if 0 not in lst ]),        \n",
    "    \"root_combine_all\":       [ index for index, lst in enumerate(root_consonants.values.flatten()) if len(lst) == unique['consonant_diacritic'] ],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination Matrices\n",
    "\n",
    "This is the full list of which Grapheme Roots combine with which Vowels and Consonant Diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_matrix(dataset, x='consonant_diacritic', y='vowel_diacritic', z='grapheme_root', format=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking = Found Dataset BUG!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This combination_matrix lists 1292 unique grapheme combinations, which is 3 less than the 1295 unique graphemes listed in the training dataset. Something is WRONG!\n",
    "\n",
    "Found a discrepency BUG is in the dataset. The following root/vowel/consonant keys have multiple unicode graphemes renderings! \n",
    "\n",
    "{'64-3-2': ['র্তী', 'র্ত্রী'],\n",
    " '64-7-2': ['র্তে', 'র্ত্রে'],\n",
    " '72-0-2': ['র্দ্র', 'র্দ']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "{\n",
    "\"combinations\": len(list(chain( *combination_matrix(dataset, x='consonant_diacritic', y='vowel_diacritic', z='grapheme_root').values.flatten() ))),\n",
    "\"unique_graphemes\": unique['grapheme']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confirm that there are no null or NaN values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.apply(lambda row: row.isnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Found the BUG! It is in the dataset!\n",
    "- There is THREE sets of unique root/vowel/consonant keys that have multiple unicode renderings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( \n",
    "    dataset\n",
    "    .groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'])\n",
    "    .nunique(dropna=False) > 1 \n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( \n",
    "    dataset\n",
    "    .groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'])\n",
    "    .nunique(dropna=False) > 1\n",
    ").query(\"grapheme != False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabled_graphemes = {\n",
    "    \"64-3-2\": dataset.query(\"grapheme_root == 64 & vowel_diacritic == 3 & consonant_diacritic == 2\")['grapheme'].unique().tolist(),\n",
    "    \"64-7-2\": dataset.query(\"grapheme_root == 64 & vowel_diacritic == 7 & consonant_diacritic == 2\")['grapheme'].unique().tolist(),\n",
    "    \"72-0-2\": dataset.query(\"grapheme_root == 72 & vowel_diacritic == 0 & consonant_diacritic == 2\")['grapheme'].unique().tolist(),\n",
    "}\n",
    "multilabled_graphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabled_grapheme_list = list(chain(*multilabled_graphemes.values())); multilabled_grapheme_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simply counts how many times each of these multi-keyed unicode graphemes is listed in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[ dataset['grapheme'].isin(multilabled_grapheme_list) ].groupby(['grapheme']).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}