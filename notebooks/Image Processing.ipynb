{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengali AI - Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob2\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "# from src.jupyter import grid_df_display, combination_matrix\n",
    "\n",
    "pd.set_option('display.max_columns',   500)\n",
    "pd.set_option('display.max_colwidth',   -1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "### Only process a single parquet file for the sake of Kaggle Kernel Memory Limits\n",
    "train = None; gc.collect()\n",
    "train = pd.concat([ pd.read_parquet(filename) for filename in sorted(glob2.glob('../input/bengaliai-cv19/train_image_data_0.parquet')) ])\n",
    "# train = pd.concat([ pd.read_parquet(filename) for filename in sorted(glob2.glob('../input/bengaliai-cv19/train_*.parquet')) ])\n",
    "# test  = pd.concat([ pd.read_parquet(filename) for filename in sorted(glob2.glob('../input/bengaliai-cv19/test_*.parquet'))  ])\n",
    "# train = train[0:8]\n",
    "train_drop = train.copy()\n",
    "train_drop.set_index('image_id', inplace=True, drop=True)\n",
    "gc.collect()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train.iloc[0,1:].values.astype('uint8').reshape(137,236); (img.shape, img.dtype)\n",
    "display( plt.imshow(img, cmap='gray') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Source: https://www.kaggle.com/c/bengaliai-cv19/discussion/122731\n",
    "# Source: https://www.kaggle.com/maxlenormand/cropping-to-character-resizing-images\n",
    "def crop_and_resize_images(df, resized_df, resize_size=236):\n",
    "    cropped_imgs = {}\n",
    "    for img_id in tqdm(range(df.shape[0])):\n",
    "        img = resized_df[img_id]\n",
    "        _, thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "        \n",
    "        idx = 0 \n",
    "        ls_xmin = []\n",
    "        ls_ymin = []\n",
    "        ls_xmax = []\n",
    "        ls_ymax = []\n",
    "        for cnt in contours:\n",
    "            idx += 1\n",
    "            x,y,w,h = cv2.boundingRect(cnt)\n",
    "            ls_xmin.append(x)\n",
    "            ls_ymin.append(y)\n",
    "            ls_xmax.append(x + w)\n",
    "            ls_ymax.append(y + h)\n",
    "        xmin = min(ls_xmin)\n",
    "        ymin = min(ls_ymin)\n",
    "        xmax = max(ls_xmax)\n",
    "        ymax = max(ls_ymax)\n",
    "\n",
    "        roi = img[ymin:ymax,xmin:xmax]\n",
    "        resized_roi = cv2.resize(roi, (resize_size, resize_size))\n",
    "        cropped_imgs[df.image_id[img_id]] = resized_roi.reshape(-1)\n",
    "        \n",
    "    resized = pd.DataFrame(cropped_imgs).T.reset_index()\n",
    "    resized.columns = resized.columns.astype(str)\n",
    "    resized.rename(columns={'index':'image_id'},inplace=True)\n",
    "    return resized #out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0       = pd.read_parquet('../input/bengaliai-cv19/train_image_data_0.parquet')\n",
    "resized    = df_0.iloc[:, 1:].values.astype(np.uint8).reshape(-1, 137,236)\n",
    "cropped_df = crop_and_resize_images(df_0, resized, 100)\n",
    "train_images  = cropped_df.iloc[0,1:].values.astype(np.uint8).reshape(-1,100,100,1)\n",
    "# train_images  = train.iloc[0,1:].values.astype(np.uint8).reshape(-1,137,236)\n",
    "# train_cropped = crop_and_resize_images(train, train_images, 100)\n",
    "# train_cropped\n",
    "cropped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# DOCS: https://keras.io/preprocessing/image/#imagedatagenerator-class\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # featurewise_center=False,             # No visible effect in plt.imgshow()\n",
    "    # samplewise_center=False,              # No visible effect in plt.imgshow()\n",
    "    # featurewise_std_normalization=False,  # No visible effect in plt.imgshow()\n",
    "    # samplewise_std_normalization=False,   # No visible effect in plt.imgshow() \n",
    "    # zca_whitening=True,                   # Kaggle, insufficent memory\n",
    "\n",
    "    rotation_range=45/2,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,        \n",
    "    brightness_range=(0.5,2),\n",
    "    shear_range=45/2,\n",
    "#     zoom_range=[-0.2, 0],\n",
    "    fill_mode='constant',\n",
    "    cval=255,        \n",
    ")\n",
    "train_datagen.fit(\n",
    "    train_images    \n",
    ")\n",
    "train_generator = train_datagen.flow(\n",
    "    train_images,\n",
    "    subset=\"training\",\n",
    "    shuffle=False,  \n",
    "    batch_size=8,        \n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "index = 0\n",
    "fig, ax = plt.subplots(figsize=(20, 10))    \n",
    "plt.axis('off')\n",
    "for batch in train_generator:\n",
    "    for img in batch:\n",
    "        index += 1\n",
    "        plt.subplot(8, 8, index)\n",
    "        plt.imshow(img.reshape(100,100), cmap='gray')        \n",
    "        # plt.imshow(img.reshape(137,236), cmap='gray')\n",
    "    if index >= 8*8: break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}